{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.add(Convolution2D(32,(3,3), input_shape=(64,64,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.add(MaxPooling2D(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=600, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(units=600, init='uniform',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(units=1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen=ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True,vertical_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2637 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory(r'C:\\Users\\KIRAN LAKHANI\\Desktop\\Cancer_CNN\\data\\train',target_size=(64,64), batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 660 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test=test_datagen.flow_from_directory(r'C:\\Users\\KIRAN LAKHANI\\Desktop\\Cancer_CNN\\data\\test',\n",
    "            target_size=(64,64),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'benign': 0, 'malignant': 1}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/150\n",
      "150/150 [==============================] - 50s 332ms/step - loss: 0.6081 - acc: 0.7048 - val_loss: 0.4342 - val_acc: 0.7859\n",
      "Epoch 2/150\n",
      "150/150 [==============================] - 42s 277ms/step - loss: 0.4488 - acc: 0.7652 - val_loss: 0.3900 - val_acc: 0.8101\n",
      "Epoch 3/150\n",
      "150/150 [==============================] - 41s 277ms/step - loss: 0.4086 - acc: 0.7992 - val_loss: 0.3818 - val_acc: 0.8205\n",
      "Epoch 4/150\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.3950 - acc: 0.8043 - val_loss: 0.3860 - val_acc: 0.7985\n",
      "Epoch 5/150\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.3930 - acc: 0.8100 - val_loss: 0.4802 - val_acc: 0.7778\n",
      "Epoch 6/150\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.3902 - acc: 0.8041 - val_loss: 0.3806 - val_acc: 0.8091\n",
      "Epoch 7/150\n",
      "150/150 [==============================] - 42s 280ms/step - loss: 0.3698 - acc: 0.8151 - val_loss: 0.3610 - val_acc: 0.8333\n",
      "Epoch 8/150\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.3593 - acc: 0.8223 - val_loss: 0.3203 - val_acc: 0.8523\n",
      "Epoch 9/150\n",
      "150/150 [==============================] - 41s 271ms/step - loss: 0.3555 - acc: 0.8307 - val_loss: 0.3346 - val_acc: 0.8354\n",
      "Epoch 10/150\n",
      "150/150 [==============================] - 40s 266ms/step - loss: 0.3464 - acc: 0.8304 - val_loss: 0.3274 - val_acc: 0.8494\n",
      "Epoch 11/150\n",
      "150/150 [==============================] - 41s 274ms/step - loss: 0.3403 - acc: 0.8328 - val_loss: 0.4127 - val_acc: 0.8091\n",
      "Epoch 12/150\n",
      "150/150 [==============================] - 41s 272ms/step - loss: 0.3358 - acc: 0.8363 - val_loss: 0.3519 - val_acc: 0.8408\n",
      "Epoch 13/150\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.3180 - acc: 0.8415 - val_loss: 0.3381 - val_acc: 0.8428\n",
      "Epoch 14/150\n",
      "150/150 [==============================] - 43s 288ms/step - loss: 0.3392 - acc: 0.8331 - val_loss: 0.3358 - val_acc: 0.8462\n",
      "Epoch 15/150\n",
      "150/150 [==============================] - 40s 264ms/step - loss: 0.3312 - acc: 0.8414 - val_loss: 0.3466 - val_acc: 0.8154\n",
      "Epoch 16/150\n",
      "150/150 [==============================] - 41s 275ms/step - loss: 0.3142 - acc: 0.8497 - val_loss: 0.3325 - val_acc: 0.8428\n",
      "Epoch 17/150\n",
      "150/150 [==============================] - 44s 295ms/step - loss: 0.3128 - acc: 0.8458 - val_loss: 0.3738 - val_acc: 0.8013\n",
      "Epoch 18/150\n",
      "150/150 [==============================] - 43s 287ms/step - loss: 0.3058 - acc: 0.8524 - val_loss: 0.3529 - val_acc: 0.8344\n",
      "Epoch 19/150\n",
      "150/150 [==============================] - 44s 294ms/step - loss: 0.3068 - acc: 0.8540 - val_loss: 0.3258 - val_acc: 0.8333\n",
      "Epoch 20/150\n",
      "150/150 [==============================] - 43s 289ms/step - loss: 0.2958 - acc: 0.8544 - val_loss: 0.3374 - val_acc: 0.8376\n",
      "Epoch 21/150\n",
      "150/150 [==============================] - 81s 541ms/step - loss: 0.2869 - acc: 0.8650 - val_loss: 0.3380 - val_acc: 0.8408\n",
      "Epoch 22/150\n",
      "150/150 [==============================] - 48s 322ms/step - loss: 0.2817 - acc: 0.8631 - val_loss: 0.3288 - val_acc: 0.8502\n",
      "Epoch 23/150\n",
      "150/150 [==============================] - 40s 270ms/step - loss: 0.2787 - acc: 0.8702 - val_loss: 0.3086 - val_acc: 0.8660\n",
      "Epoch 24/150\n",
      "150/150 [==============================] - 44s 291ms/step - loss: 0.2827 - acc: 0.8642 - val_loss: 0.4544 - val_acc: 0.7714\n",
      "Epoch 25/150\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.2852 - acc: 0.8648 - val_loss: 0.3256 - val_acc: 0.8460\n",
      "Epoch 26/150\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.2721 - acc: 0.8719 - val_loss: 0.3311 - val_acc: 0.8376\n",
      "Epoch 27/150\n",
      "150/150 [==============================] - 40s 269ms/step - loss: 0.2567 - acc: 0.8817 - val_loss: 0.3225 - val_acc: 0.8428\n",
      "Epoch 28/150\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.2595 - acc: 0.8792 - val_loss: 0.3295 - val_acc: 0.8280\n",
      "Epoch 29/150\n",
      "150/150 [==============================] - 44s 291ms/step - loss: 0.2560 - acc: 0.8815 - val_loss: 0.3505 - val_acc: 0.8407\n",
      "Epoch 30/150\n",
      "150/150 [==============================] - 45s 298ms/step - loss: 0.2425 - acc: 0.8912 - val_loss: 0.3192 - val_acc: 0.8650\n",
      "Epoch 31/150\n",
      "150/150 [==============================] - 45s 303ms/step - loss: 0.2376 - acc: 0.8912 - val_loss: 0.3414 - val_acc: 0.8494\n",
      "Epoch 32/150\n",
      "150/150 [==============================] - 44s 296ms/step - loss: 0.2406 - acc: 0.8903 - val_loss: 0.3231 - val_acc: 0.8523\n",
      "Epoch 33/150\n",
      "150/150 [==============================] - 50s 335ms/step - loss: 0.2383 - acc: 0.8950 - val_loss: 0.3717 - val_acc: 0.8387\n",
      "Epoch 34/150\n",
      "150/150 [==============================] - 49s 327ms/step - loss: 0.2306 - acc: 0.8975 - val_loss: 0.4394 - val_acc: 0.7943\n",
      "Epoch 35/150\n",
      "150/150 [==============================] - 48s 322ms/step - loss: 0.2180 - acc: 0.9053 - val_loss: 0.3558 - val_acc: 0.8579\n",
      "Epoch 36/150\n",
      "150/150 [==============================] - 44s 292ms/step - loss: 0.2147 - acc: 0.9009 - val_loss: 0.3373 - val_acc: 0.8449\n",
      "Epoch 37/150\n",
      "150/150 [==============================] - 46s 305ms/step - loss: 0.2143 - acc: 0.9057 - val_loss: 0.3599 - val_acc: 0.8534\n",
      "Epoch 38/150\n",
      "150/150 [==============================] - 44s 291ms/step - loss: 0.2166 - acc: 0.9056 - val_loss: 0.3428 - val_acc: 0.8579\n",
      "Epoch 39/150\n",
      "150/150 [==============================] - 41s 275ms/step - loss: 0.2095 - acc: 0.9045 - val_loss: 0.3350 - val_acc: 0.8660\n",
      "Epoch 40/150\n",
      "150/150 [==============================] - 40s 269ms/step - loss: 0.1988 - acc: 0.9097 - val_loss: 0.3829 - val_acc: 0.8526\n",
      "Epoch 41/150\n",
      "150/150 [==============================] - 44s 295ms/step - loss: 0.2252 - acc: 0.8976 - val_loss: 0.3035 - val_acc: 0.8534\n",
      "Epoch 42/150\n",
      "150/150 [==============================] - 40s 267ms/step - loss: 0.1986 - acc: 0.9123 - val_loss: 0.3572 - val_acc: 0.8611\n",
      "Epoch 43/150\n",
      "150/150 [==============================] - 46s 308ms/step - loss: 0.1862 - acc: 0.9155 - val_loss: 0.3614 - val_acc: 0.8565\n",
      "Epoch 44/150\n",
      "150/150 [==============================] - 45s 298ms/step - loss: 0.1930 - acc: 0.9187 - val_loss: 0.3689 - val_acc: 0.8386\n",
      "Epoch 45/150\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.1817 - acc: 0.9212 - val_loss: 0.3734 - val_acc: 0.8429\n",
      "Epoch 46/150\n",
      "150/150 [==============================] - 48s 318ms/step - loss: 0.2004 - acc: 0.9130 - val_loss: 0.3724 - val_acc: 0.8354\n",
      "Epoch 47/150\n",
      "150/150 [==============================] - 46s 307ms/step - loss: 0.1846 - acc: 0.9203 - val_loss: 0.4453 - val_acc: 0.8216\n",
      "Epoch 48/150\n",
      "150/150 [==============================] - 46s 308ms/step - loss: 0.1790 - acc: 0.9224 - val_loss: 0.3800 - val_acc: 0.8681\n",
      "Epoch 49/150\n",
      "150/150 [==============================] - 43s 289ms/step - loss: 0.1860 - acc: 0.9204 - val_loss: 0.3881 - val_acc: 0.8494\n",
      "Epoch 50/150\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.1762 - acc: 0.9241 - val_loss: 0.3312 - val_acc: 0.8597\n",
      "Epoch 51/150\n",
      "150/150 [==============================] - 45s 303ms/step - loss: 0.1814 - acc: 0.9235 - val_loss: 0.3245 - val_acc: 0.8629\n",
      "Epoch 52/150\n",
      "150/150 [==============================] - 44s 294ms/step - loss: 0.1645 - acc: 0.9329 - val_loss: 0.3519 - val_acc: 0.8611\n",
      "Epoch 53/150\n",
      "150/150 [==============================] - 45s 299ms/step - loss: 0.1685 - acc: 0.9314 - val_loss: 0.3687 - val_acc: 0.8523\n",
      "Epoch 54/150\n",
      "150/150 [==============================] - 44s 295ms/step - loss: 0.1663 - acc: 0.9269 - val_loss: 0.3465 - val_acc: 0.8729\n",
      "Epoch 55/150\n",
      "150/150 [==============================] - 41s 272ms/step - loss: 0.1574 - acc: 0.9329 - val_loss: 0.3205 - val_acc: 0.8724\n",
      "Epoch 56/150\n",
      "150/150 [==============================] - 40s 268ms/step - loss: 0.1505 - acc: 0.9384 - val_loss: 0.3620 - val_acc: 0.8707\n",
      "Epoch 57/150\n",
      "150/150 [==============================] - 41s 272ms/step - loss: 0.1523 - acc: 0.9345 - val_loss: 0.3916 - val_acc: 0.8544\n",
      "Epoch 58/150\n",
      "150/150 [==============================] - 40s 266ms/step - loss: 0.1415 - acc: 0.9432 - val_loss: 0.4025 - val_acc: 0.8608\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 40s 267ms/step - loss: 0.1415 - acc: 0.9374 - val_loss: 0.4019 - val_acc: 0.8622\n",
      "Epoch 60/150\n",
      "150/150 [==============================] - 40s 267ms/step - loss: 0.1577 - acc: 0.9332 - val_loss: 0.4408 - val_acc: 0.8344\n",
      "Epoch 61/150\n",
      "150/150 [==============================] - 41s 273ms/step - loss: 0.1386 - acc: 0.9433 - val_loss: 0.4518 - val_acc: 0.8536\n",
      "Epoch 62/150\n",
      "150/150 [==============================] - 41s 276ms/step - loss: 0.1169 - acc: 0.9584 - val_loss: 0.4724 - val_acc: 0.8534\n",
      "Epoch 63/150\n",
      "150/150 [==============================] - 43s 288ms/step - loss: 0.1171 - acc: 0.9516 - val_loss: 0.5632 - val_acc: 0.8312\n",
      "Epoch 64/150\n",
      "150/150 [==============================] - 44s 291ms/step - loss: 0.1469 - acc: 0.9365 - val_loss: 0.3812 - val_acc: 0.8439\n",
      "Epoch 65/150\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.1353 - acc: 0.9453 - val_loss: 0.3516 - val_acc: 0.8734\n",
      "Epoch 66/150\n",
      "150/150 [==============================] - 44s 293ms/step - loss: 0.1185 - acc: 0.9577 - val_loss: 0.4536 - val_acc: 0.8387\n",
      "Epoch 67/150\n",
      "150/150 [==============================] - 44s 295ms/step - loss: 0.1186 - acc: 0.9498 - val_loss: 0.3870 - val_acc: 0.8576\n",
      "Epoch 68/150\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.1187 - acc: 0.9523 - val_loss: 0.4131 - val_acc: 0.8686\n",
      "Epoch 69/150\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.1189 - acc: 0.9530 - val_loss: 0.3944 - val_acc: 0.8481\n",
      "Epoch 70/150\n",
      "150/150 [==============================] - 44s 293ms/step - loss: 0.1031 - acc: 0.9560 - val_loss: 0.5693 - val_acc: 0.8323\n",
      "Epoch 71/150\n",
      "150/150 [==============================] - 44s 292ms/step - loss: 0.1235 - acc: 0.9491 - val_loss: 0.5548 - val_acc: 0.8397\n",
      "Epoch 72/150\n",
      "150/150 [==============================] - 44s 296ms/step - loss: 0.1217 - acc: 0.9499 - val_loss: 0.4370 - val_acc: 0.8354\n",
      "Epoch 73/150\n",
      "150/150 [==============================] - 41s 276ms/step - loss: 0.1034 - acc: 0.9573 - val_loss: 0.4836 - val_acc: 0.8408\n",
      "Epoch 74/150\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.1015 - acc: 0.9625 - val_loss: 0.4881 - val_acc: 0.8544\n",
      "Epoch 75/150\n",
      "150/150 [==============================] - 44s 291ms/step - loss: 0.0877 - acc: 0.9667 - val_loss: 0.4263 - val_acc: 0.8526\n",
      "Epoch 76/150\n",
      "150/150 [==============================] - 44s 295ms/step - loss: 0.1277 - acc: 0.9478 - val_loss: 0.4759 - val_acc: 0.8534\n",
      "Epoch 77/150\n",
      "150/150 [==============================] - 41s 277ms/step - loss: 0.1039 - acc: 0.9567 - val_loss: 0.4756 - val_acc: 0.8248\n",
      "Epoch 78/150\n",
      "150/150 [==============================] - 40s 266ms/step - loss: 0.1243 - acc: 0.9498 - val_loss: 0.4771 - val_acc: 0.8618\n",
      "Epoch 79/150\n",
      "150/150 [==============================] - 40s 268ms/step - loss: 0.0923 - acc: 0.9624 - val_loss: 0.4964 - val_acc: 0.8270\n",
      "Epoch 80/150\n",
      "150/150 [==============================] - 43s 288ms/step - loss: 0.0977 - acc: 0.9609 - val_loss: 0.5174 - val_acc: 0.8365\n",
      "Epoch 81/150\n",
      "150/150 [==============================] - 44s 296ms/step - loss: 0.0904 - acc: 0.9642 - val_loss: 0.4380 - val_acc: 0.8776\n",
      "Epoch 82/150\n",
      "150/150 [==============================] - 44s 295ms/step - loss: 0.0921 - acc: 0.9659 - val_loss: 0.6067 - val_acc: 0.8280\n",
      "Epoch 83/150\n",
      "150/150 [==============================] - 44s 293ms/step - loss: 0.0930 - acc: 0.9647 - val_loss: 0.4586 - val_acc: 0.8650\n",
      "Epoch 84/150\n",
      "150/150 [==============================] - 44s 295ms/step - loss: 0.0786 - acc: 0.9725 - val_loss: 0.4235 - val_acc: 0.8494\n",
      "Epoch 85/150\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.0911 - acc: 0.9661 - val_loss: 0.5083 - val_acc: 0.8597\n",
      "Epoch 86/150\n",
      "150/150 [==============================] - 44s 295ms/step - loss: 0.0857 - acc: 0.9668 - val_loss: 0.4004 - val_acc: 0.8597\n",
      "Epoch 87/150\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.0702 - acc: 0.9733 - val_loss: 0.5263 - val_acc: 0.8536\n",
      "Epoch 88/150\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.0763 - acc: 0.9731 - val_loss: 0.5862 - val_acc: 0.8597\n",
      "Epoch 89/150\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.0807 - acc: 0.9677 - val_loss: 0.5528 - val_acc: 0.8397\n",
      "Epoch 90/150\n",
      "150/150 [==============================] - 44s 292ms/step - loss: 0.0706 - acc: 0.9756 - val_loss: 0.6217 - val_acc: 0.8365\n",
      "Epoch 91/150\n",
      "150/150 [==============================] - 44s 292ms/step - loss: 0.0935 - acc: 0.9637 - val_loss: 0.5317 - val_acc: 0.8590\n",
      "Epoch 92/150\n",
      "150/150 [==============================] - 44s 296ms/step - loss: 0.0822 - acc: 0.9664 - val_loss: 0.5031 - val_acc: 0.8650\n",
      "Epoch 93/150\n",
      "150/150 [==============================] - 44s 296ms/step - loss: 0.0783 - acc: 0.9710 - val_loss: 0.5630 - val_acc: 0.8502\n",
      "Epoch 94/150\n",
      "150/150 [==============================] - 42s 280ms/step - loss: 0.0647 - acc: 0.9764 - val_loss: 0.4878 - val_acc: 0.8686\n",
      "Epoch 95/150\n",
      "150/150 [==============================] - 44s 294ms/step - loss: 0.0684 - acc: 0.9717 - val_loss: 0.5280 - val_acc: 0.8586\n",
      "Epoch 96/150\n",
      "150/150 [==============================] - 44s 294ms/step - loss: 0.0708 - acc: 0.9739 - val_loss: 0.6201 - val_acc: 0.8419\n",
      "Epoch 97/150\n",
      "150/150 [==============================] - 44s 292ms/step - loss: 0.0795 - acc: 0.9685 - val_loss: 0.5335 - val_acc: 0.8576\n",
      "Epoch 98/150\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.0707 - acc: 0.9741 - val_loss: 0.5600 - val_acc: 0.8558\n",
      "Epoch 99/150\n",
      "150/150 [==============================] - 43s 288ms/step - loss: 0.0938 - acc: 0.9652 - val_loss: 0.6431 - val_acc: 0.8154\n",
      "Epoch 100/150\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.0586 - acc: 0.9775 - val_loss: 0.4910 - val_acc: 0.8639\n",
      "Epoch 101/150\n",
      "150/150 [==============================] - 43s 285ms/step - loss: 0.0705 - acc: 0.9734 - val_loss: 0.5502 - val_acc: 0.8686\n",
      "Epoch 102/150\n",
      "150/150 [==============================] - 44s 295ms/step - loss: 0.0674 - acc: 0.9754 - val_loss: 0.4819 - val_acc: 0.8481\n",
      "Epoch 103/150\n",
      "150/150 [==============================] - 45s 300ms/step - loss: 0.0579 - acc: 0.9797 - val_loss: 0.5529 - val_acc: 0.8494\n",
      "Epoch 104/150\n",
      "150/150 [==============================] - 44s 294ms/step - loss: 0.0522 - acc: 0.9819 - val_loss: 0.6111 - val_acc: 0.8397\n",
      "Epoch 105/150\n",
      "150/150 [==============================] - 44s 293ms/step - loss: 0.0623 - acc: 0.9760 - val_loss: 0.5572 - val_acc: 0.8643\n",
      "Epoch 106/150\n",
      "150/150 [==============================] - 44s 292ms/step - loss: 0.0559 - acc: 0.9802 - val_loss: 0.6173 - val_acc: 0.8449\n",
      "Epoch 107/150\n",
      "150/150 [==============================] - 44s 293ms/step - loss: 0.1162 - acc: 0.9609 - val_loss: 0.6450 - val_acc: 0.8407\n",
      "Epoch 108/150\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.0888 - acc: 0.9709 - val_loss: 0.4326 - val_acc: 0.8857\n",
      "Epoch 109/150\n",
      "150/150 [==============================] - 41s 274ms/step - loss: 0.0650 - acc: 0.9767 - val_loss: 0.5052 - val_acc: 0.8597\n",
      "Epoch 110/150\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.0599 - acc: 0.9755 - val_loss: 0.6270 - val_acc: 0.8344\n",
      "Epoch 111/150\n",
      "150/150 [==============================] - 41s 272ms/step - loss: 0.0475 - acc: 0.9826 - val_loss: 0.5069 - val_acc: 0.8555\n",
      "Epoch 112/150\n",
      "150/150 [==============================] - 43s 287ms/step - loss: 0.0439 - acc: 0.9837 - val_loss: 0.6440 - val_acc: 0.8483\n",
      "Epoch 113/150\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.0568 - acc: 0.9806 - val_loss: 0.6634 - val_acc: 0.8470\n",
      "Epoch 114/150\n",
      "150/150 [==============================] - 43s 283ms/step - loss: 0.0560 - acc: 0.9794 - val_loss: 0.7972 - val_acc: 0.8281\n",
      "Epoch 115/150\n",
      "150/150 [==============================] - 43s 287ms/step - loss: 0.0511 - acc: 0.9820 - val_loss: 0.5754 - val_acc: 0.8568\n",
      "Epoch 116/150\n",
      "150/150 [==============================] - 43s 289ms/step - loss: 0.0321 - acc: 0.9901 - val_loss: 0.6529 - val_acc: 0.8586\n",
      "Epoch 117/150\n",
      "150/150 [==============================] - 44s 290ms/step - loss: 0.0452 - acc: 0.9844 - val_loss: 0.8144 - val_acc: 0.8472\n",
      "Epoch 118/150\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.0714 - acc: 0.9753 - val_loss: 0.6482 - val_acc: 0.8449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/150\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.0663 - acc: 0.9770 - val_loss: 0.5834 - val_acc: 0.8579\n",
      "Epoch 120/150\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.0404 - acc: 0.9865 - val_loss: 0.5473 - val_acc: 0.8608\n",
      "Epoch 121/150\n",
      "150/150 [==============================] - 41s 275ms/step - loss: 0.0712 - acc: 0.9734 - val_loss: 0.7329 - val_acc: 0.8376\n",
      "Epoch 122/150\n",
      "150/150 [==============================] - 43s 287ms/step - loss: 0.0461 - acc: 0.9837 - val_loss: 0.7566 - val_acc: 0.8397\n",
      "Epoch 123/150\n",
      "150/150 [==============================] - 40s 265ms/step - loss: 0.0562 - acc: 0.9804 - val_loss: 0.7138 - val_acc: 0.8449\n",
      "Epoch 124/150\n",
      "150/150 [==============================] - 41s 274ms/step - loss: 0.0578 - acc: 0.9784 - val_loss: 0.5425 - val_acc: 0.8654\n",
      "Epoch 125/150\n",
      "150/150 [==============================] - 41s 276ms/step - loss: 0.0560 - acc: 0.9777 - val_loss: 0.6405 - val_acc: 0.8502\n",
      "Epoch 126/150\n",
      "150/150 [==============================] - 41s 273ms/step - loss: 0.0404 - acc: 0.9870 - val_loss: 0.5893 - val_acc: 0.8632\n",
      "Epoch 127/150\n",
      "150/150 [==============================] - 44s 290ms/step - loss: 0.0506 - acc: 0.9810 - val_loss: 0.5925 - val_acc: 0.8608\n",
      "Epoch 128/150\n",
      "150/150 [==============================] - 44s 293ms/step - loss: 0.0504 - acc: 0.9822 - val_loss: 0.6530 - val_acc: 0.8460\n",
      "Epoch 129/150\n",
      "150/150 [==============================] - 41s 276ms/step - loss: 0.0410 - acc: 0.9865 - val_loss: 0.5443 - val_acc: 0.8643\n",
      "Epoch 130/150\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.0288 - acc: 0.9900 - val_loss: 0.7017 - val_acc: 0.8513\n",
      "Epoch 131/150\n",
      "150/150 [==============================] - 42s 282ms/step - loss: 0.0410 - acc: 0.9855 - val_loss: 0.5129 - val_acc: 0.8600\n",
      "Epoch 132/150\n",
      "150/150 [==============================] - 42s 277ms/step - loss: 0.0403 - acc: 0.9855 - val_loss: 0.6609 - val_acc: 0.8576\n",
      "Epoch 133/150\n",
      "150/150 [==============================] - 42s 277ms/step - loss: 0.0381 - acc: 0.9873 - val_loss: 0.6516 - val_acc: 0.8429\n",
      "Epoch 134/150\n",
      "150/150 [==============================] - 41s 275ms/step - loss: 0.0624 - acc: 0.9779 - val_loss: 0.5609 - val_acc: 0.8544\n",
      "Epoch 135/150\n",
      "150/150 [==============================] - 42s 279ms/step - loss: 0.0485 - acc: 0.9825 - val_loss: 0.7559 - val_acc: 0.8449\n",
      "Epoch 136/150\n",
      "150/150 [==============================] - 42s 283ms/step - loss: 0.0704 - acc: 0.9754 - val_loss: 0.7019 - val_acc: 0.8590\n",
      "Epoch 137/150\n",
      "150/150 [==============================] - 41s 276ms/step - loss: 0.0351 - acc: 0.9877 - val_loss: 0.6549 - val_acc: 0.8386\n",
      "Epoch 138/150\n",
      "150/150 [==============================] - 43s 288ms/step - loss: 0.0430 - acc: 0.9832 - val_loss: 0.6855 - val_acc: 0.8451\n",
      "Epoch 139/150\n",
      "150/150 [==============================] - 42s 278ms/step - loss: 0.0445 - acc: 0.9842 - val_loss: 0.6240 - val_acc: 0.8586\n",
      "Epoch 140/150\n",
      "150/150 [==============================] - 42s 281ms/step - loss: 0.0261 - acc: 0.9910 - val_loss: 0.7166 - val_acc: 0.8643\n",
      "Epoch 141/150\n",
      "150/150 [==============================] - 43s 287ms/step - loss: 0.0416 - acc: 0.9854 - val_loss: 0.6672 - val_acc: 0.8534\n",
      "Epoch 142/150\n",
      "150/150 [==============================] - 43s 289ms/step - loss: 0.0307 - acc: 0.9889 - val_loss: 0.8019 - val_acc: 0.8460\n",
      "Epoch 143/150\n",
      "150/150 [==============================] - 44s 291ms/step - loss: 0.0244 - acc: 0.9925 - val_loss: 0.8218 - val_acc: 0.8665\n",
      "Epoch 144/150\n",
      "150/150 [==============================] - 44s 293ms/step - loss: 0.0297 - acc: 0.9896 - val_loss: 0.7189 - val_acc: 0.8418\n",
      "Epoch 145/150\n",
      "150/150 [==============================] - 44s 296ms/step - loss: 0.0621 - acc: 0.9782 - val_loss: 0.6392 - val_acc: 0.8440\n",
      "Epoch 146/150\n",
      "150/150 [==============================] - 43s 286ms/step - loss: 0.0300 - acc: 0.9901 - val_loss: 0.5123 - val_acc: 0.8692\n",
      "Epoch 147/150\n",
      "150/150 [==============================] - 41s 274ms/step - loss: 0.0336 - acc: 0.9879 - val_loss: 0.7590 - val_acc: 0.8429\n",
      "Epoch 148/150\n",
      "150/150 [==============================] - 43s 284ms/step - loss: 0.0403 - acc: 0.9857 - val_loss: 0.6561 - val_acc: 0.8418\n",
      "Epoch 149/150\n",
      "150/150 [==============================] - 44s 290ms/step - loss: 0.0333 - acc: 0.9883 - val_loss: 0.7192 - val_acc: 0.8376\n",
      "Epoch 150/150\n",
      "150/150 [==============================] - 43s 289ms/step - loss: 0.0503 - acc: 0.9824 - val_loss: 0.5427 - val_acc: 0.8558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x280ee1e4710>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=150, epochs=150, validation_data=x_test,validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cancer_cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
